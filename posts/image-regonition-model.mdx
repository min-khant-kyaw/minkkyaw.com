---
title: "Image Recognition model with TensorFlow Lite Part 1"
date: "2020-08-10"
author: "Min Khant Kyaw"
excerpt: "Making an image recognition model to work with Raspberry Pi"
read: "10 minute read"
---

# TensorFlow Lite Model Training Guide

## Brief Summary
This is a guide referenced from multiple sources cited below for creating a Machine Learning Model that can be deployed to small form computers such as a Raspberry Pi or an Android phone. The model will be a quantized SSD-MobileNet which is trained using TensorFlow and exported in a frozen graph for TensorFlow Lite. This guide is mainly catered towards Windows Users. For Linux users, you can still follow the guide, but will have to reference [TensorFlow's website](https://www.tensorflow.org/install) for further installation details.

TensorFlow Lite is an optimised framework to help developers run TensorFlow models on resource-constrained devices such as a Raspberry Pi or a mobile device. This guide will provide a step by step instruction on how to train a TensorFlow Object Detection model and convert to a more optimised TensorFlow Lite format which then can be deployed to a Raspberry Pi or an Android phone.

This guide will be using an Anaconda virtual environment and I'll be training a shoe detector model to detect different types of shoes. The intent of this detection model is mainly to recognise the type of shoe detected by the camera. For demo purposes, I'll mainly be using recognisable and popular brands such as Nike and Adidas to differentiate the type of shoes.

### To-do list
1. [Installing required libraries and packages (Anaconda, CUDA & cdDNN)](https://github.com/min-khant-kyaw/image_classification/blob/master/README.md#1-installing-required-libraries-and-packages-anaconda-cuda--cddnn)
2. [Setting up Directory and Anaconda Virtual Enviroment](https://github.com/min-khant-kyaw/image_classification/blob/master/README.md#2-setting-up-directory-and-anaconda-virtual-environment)
3. [Gathering Pictures](https://github.com/min-khant-kyaw/image_classification/blob/master/README.md#3-gathering-pictures)
4. [Labelling Pictures](https://github.com/min-khant-kyaw/image_classification/blob/master/README.md#4-labelling-pictures)
5. [Generating Training Data](https://github.com/min-khant-kyaw/image_classification/blob/master/README.md#5-generating-training-data)
6. [Creating Label Map and Configuring Training](https://github.com/min-khant-kyaw/image_classification/blob/master/README.md#6-creating-label-map-and-configuring-training)
7. [Training The Model](https://github.com/min-khant-kyaw/image_classification/blob/master/README.md#7-training-the-model)

## 1. Installing required Libraries and packages (Anaconda, CUDA & cdDNN)

Firstly, I would recommend everyone to first download and install [Python](https://www.python.org/downloads/windows/), where v3.6.x would be my recommended version as most libraries work well with v3.6.x. After installing Python, I would follow this [Youtube video by Mark Jay](https://www.youtube.com/watch?v=RplXYjxgZbw) which shows the process of how to install Anaconda, CUDA and cuDNN. Installation of TensorFlow is not needed as it will be installed in the later stages. This video is also made for TensorFlow-GPU v1.4, so download and istall the CUDA and cuDNN versions for the latest TensorFlow version instead of the versions stated here. The compability of CUDA and cuDNN versions needed for TensorFlow is stated in their [official website](https://www.tensorflow.org/install/gpu). You can also refer to this [table](https://www.tensorflow.org/install/source#tested_build_configurations) to see the compatible version of CUDA and cuDNN for TensorFlow.

When installing Anaconda, it will show that the Anaconda version is meant for Python >v3.8. It is fine to install it that way as we will be setting a virtual environment with Python v3.6.x later on.

Versions I was using during the time of writing this
Python: 3.6.8
Anaconda: 
TensorFlow-GPU:
CUDA:
cuDNN:

## 2. Setting up Directory and Anaconda Virtual Environment

### 2a. Download TensorFlow Object Detection API from GitHub

Create a new folder, and name it as TensorFlow(itc, I will be using E:\TensorFlow). This folder will contain the full TensorFlow Object Detection framework, as well as important data such as training images, training data, testing images, configuration files and everything else needed for the object detection classifier.

[Download](https://github.com/tensorflow/models) the TensorFlow object detection repo by click the ```Clone or download``` button and downloading the zip file. Once downloadeed, extract the zip file and place the extracted folder in the directory created(E:\TensorFlow).


## 3. Gathering Pictures
To achieve a good TensorFlow model, you will need a lot of pictures to train the model. You can either collect the data yourself using your phone or use a python image scraping tool to achieve the exact number of pictures you want. I will be using the latter method with the help of ```flickr_scraper```.


### 3a. Downloading
With reference to [this](https://github.com/ultralytics/flickr_scraper), I will be downloading ```flickr_scraper``` to my PC.

```
git clone https://github.com/ultralytics/flickr_scraper
cd flickr_scraper
pip install -U -r requirements.txt
```
This will download flickr_scraper to your PC, but you will not be able to the scraper just yet.
You will need to Sign Up for flickr and request for an API key [here](https://www.flickr.com/services/apps/create/apply)

Open ```flickr_scraper.py```and input the API key and secret in Line 9 & 10

```
key = ''
secret = ''
```

Now you have successfully setup your scraper and you are now able to execute it by running the following command

> python3 flickr_scraper.py --search "{name}" --n {num} --download
```
python flickr_scraper.py --search "Nike Jordan 1 shoes" --n 100 --download
```

The images download will be automatically saved in ```flickr_scraper\images\{name}``` folder with randomised names.

### 3b. Resizing and Renaming
Now that you have downloaded all the files, it's time to reaname and resize the images.
It is generally good to have a smaller sample of images (size as low as 200KB) so that the training of the model will not take alot of time. It is fine to train the label and train the model as it is, but due to some images being extremely huge in size such as 4000x7000 pixels, the training will take alot more time. 
It is also a good practice to ensure that all your files are named properly. So, to reduce the filesize as well as the size of the image itself while renaming the file, open up ```resizer.py``` in the Python IDE that comes with the installation of python.



Great! This is all you will need for gathering pictures. Next, we will be labelling every picture that you want to train.


## 4. Labelling Pictures
Now to the very FUN part. Yay. This is the step where you will have to manually select the areas that you want the model to be trained. 
LabelImg is a great tool to help with the labelling process. It's [Github page](https://github.com/tzutalin/labelImg) provides clear instructions on how to install and use this tool.

If you can't be bothered to read instructions, just download the tool from [here](https://www.dropbox.com/s/tq7zfrcwl44vxan/windows_v1.6.0.zip?dl=1)

Once LabelImg is launched, make sure to ```Change Dir```to your train directory and ```Change Save Dir```to the same directory as well. Also, repeat the same process for test directory.

I was tasked to label 4000+ images. No problem, I was being paid to do this...
<p>
  <img width="300" height="300" src="https://media1.tenor.com/images/e8811ef763720c5a399379dd68b641f9/tenor.gif?itemid=6139291" title="Not paid enough for this" />
</p>

After labelling an image, you can see that LabelImg will help create a .xml file containing the label data for each image. These xml files will help generate TFRecords which is one of the inputs to the TensorFlow trainer.

## 5. Generating Training Data
After done labelling, it is now time to generate data to train the TensorFlow model. We will be generating TFRecords that will serve as training to the TensorFlow training model. We will be using xml_to_cs.py and generate_tfrecord.py scripts from [Dat Tranâ€™s Raccoon Detector dataset](http://github.com/datitran/raccoon_dataset) while making slight modifications to our scripts to work with our directory structure.


## 6. Creating Label Map and Configuring Training



## 7. Training The Model




